# Sequence to Sequence Learning with Neural Networks (2014)

ğŸ“„ Paper Link: https://arxiv.org/abs/1409.3215  
ğŸ“‚ Local PDF: ../../1409.3215v3.pdf  
âœï¸ Authors: Sutskever, Vinyals & Le  
ğŸ« Published in: NeurIPS 2014  

---

## ğŸ¯ Objective
Introduce a **general sequence-to-sequence learning framework** using **two LSTM networks** (Encoder + Decoder) to perform machine translation and other sequence prediction tasks.

---

## ğŸ§  Key Contributions
- âœ… Introduced the **Encoderâ€“Decoder** architecture
- âœ… Demonstrated strong performance in **machine translation**
- âœ… Showed that **sequence lengths can differ** between input/output
- âœ… Introduced key technique: **Reverse input sequence â†’ +improves learning**

---

## ğŸ§ª Methodology
| Component | Role |
|----------|------|
| Encoder LSTM | Encodes full input sequence into a vector |
| Decoder LSTM | Generates output sequence step-by-step |
| Teacher forcing | Helps learning during training |

Key idea:
- Encoder compresses the entire sequence into a **fixed-length vector**
- Decoder **reconstructs** the sequence from that vector

âš ï¸ Limitation: Bottleneck when sequences are long.

---

## ğŸ“ˆ Results
- Improved BLEU scores vs. previous MT systems
- First successful demonstration of **end-to-end learned translation**
- Established foundation for all **modern autoregressive models**

---

## âœ… Strengths
- Handles **variable-length** sequences
- Works well for short-to-moderate horizons
- Clear and elegant architecture

---

## âš ï¸ Limitations
- Memory bottleneck â†’ struggles with **long sequences**
- No attention â†’ decoder lacks direct access to full input sequence
- Training can be slow

---

## ğŸ¤ Relevance to CAST Project
âœ” Base conceptual framework for sequence forecasting  
âœ” Helps contextualizar **por que razÃ£o** Transformers surgiram  
âœ” SerÃ¡ importante na tua RevisÃ£o de Literatura como **ponto histÃ³rico**  
âœ” Bom baseline para comparaÃ§Ã£o de resultados com o CAST

---

## ğŸ” Tags
Seq2Seq â€¢ LSTM â€¢ Encoderâ€“Decoder â€¢ Sequence Modeling
