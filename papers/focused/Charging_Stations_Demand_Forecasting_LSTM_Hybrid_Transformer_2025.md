# Charging Stations Demand Forecasting using LSTM-Based Hybrid Transformer Model (2025)

ğŸ“„ Paper Link: https://doi.org/10.1038/s41598-025-20421-y  
ğŸ“‚ Local PDF: ../../s41598-025-20421-y.pdf  
âœï¸ Authors: Kanters et al.  
ğŸ« Published in: Scientific Reports (Nature Portfolio), 2025  

---

## ğŸ¯ Objective
Propose a **hybrid LSTM-Transformer model** to improve EV charging **demand forecasting** accuracy by learning:

- Short-term temporal dependencies (via LSTM)
- Long-term relationships and attention patterns (via Transformer)

Target use case:
ğŸ“Œ Help decision-making for **charging infrastructure planning**

---

## ğŸ§  Key Contributions
- âœ… Novel **hybrid architecture** combining strengths of:
  - LSTM â†’ local temporal memory
  - Transformer â†’ global attention for long sequences
- âœ… Demonstrates real-world performance on EV charging datasets
- âœ… Shows attention improves modeling of **spatial-temporal dependencies**
- âœ… Offers a balance between **accuracy** and **computational cost**

---

## ğŸ§ª Methodology

| Component | Role |
|----------|------|
| LSTM layers | Extract near-term dynamics |
| Transformer encoder | Capture long-range dependencies |
| Fusion layer | Combine representations |
| Dense head | Multi-step forecasting output |

Metrics:
- MAE
- RMSE
- MAPE

Comparison models:
- Standalone LSTM
- ARIMA
- Random Forest

---

## ğŸ“ˆ Results

| Model | Performance |
|-------|-------------|
| Hybrid Transformer-LSTM | â­ Best |
| LSTM only | Good but weaker long-term |
| ARIMA | Struggles at peak hours |

Insights:
- More connectors â†’ higher variance â†’ harder peaks
- Spatial location strongly influences demand

ğŸ§  High take-away:
â¡ï¸ Pure deep learning already **beats classical models**  
â¡ï¸ Adding attention **further improves forecast quality**

---

## âœ… Strengths
- Very aligned with **spatio-temporal forecasting**
- Well-balanced architecture complexity
- Highly relevant to real EV infrastructure systems

---

## âš ï¸ Limitations
- Focuses only on **load** â€” does not yet model **availability state**
- Dataset not public â†’ reproducibility limitada
- Interpretability limitada vs TFT approach

---

## ğŸ“Š Metrics & Results Summary

| Model | RMSE â†“ | MAPE â†“ | MAE â†“ | Observation |
|-------|--------|--------|-------|-------------|
| Hybrid Transformerâ€“LSTM | â­ Best | â­ Best | â­ Best | Captures long-range + local dynamics; most robust at multi-step horizons |
| LSTM (standalone) | Medium | Medium | Medium | Good short-term memory; weaker for long seasonal effects |
| ARIMA / Classical | Weak | Weak | Weak | Struggles during peak hours and regime shifts |

Key insights:
- Attention layers **improve long-horizon accuracy** over LSTM-only
- Performance degrades slightly in **high-variance peak periods**, but still superior to baselines
- Spatial/context features materially **boost** results (e.g., station/location effects)

---

## ğŸ¤ Relevance to CAST Project
â­â­â­ ALTAMENTE RELEVANTE â­â­â­

âœ” Justifica:
- Hybrid models (RNN + Transformer)
- Attention for EV charging
- Focus on real operational use cases

âœ” AjudarÃ¡ muito na tua **IntroduÃ§Ã£o + Estado da Arte**  
âœ” Excelente referÃªncia para comparar resultados do CAST

---

## ğŸ” Tags
EV Charging â€¢ Hybrid Model â€¢ Transformer â€¢ LSTM â€¢ Demand Forecasting
